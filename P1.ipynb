{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Finding Lane Lines on the Road\n",
    "\n",
    "Below is the code pipeline used to find lanes road images as part of the first project in the Self Driving Car course offered by Udacity. Reflections about the pipeline and its short comings are at the very bottom of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# import all packages necessary to make this notebook run\n",
    "from moviepy.editor import VideoFileClip                                         \n",
    "from IPython.display import HTML   \n",
    "import matplotlib.pyplot as plot\n",
    "import matplotlib.image as mimage\n",
    "import numpy\n",
    "import cv2\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x10cc2f940>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define a test image to quickly test image transform functions\n",
    "test_image = mimage.imread('test_images/solidWhiteRight.jpg')\n",
    "plot.imshow(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# paths where test videos are taken and outputed\n",
    "video_file_path = 'test_videos/'\n",
    "video_output_path = 'test_videos_output/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# apply grayscale transform on image\n",
    "def gray_transform(image):\n",
    "    image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    return image_gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# apply guassian blur on image.\n",
    "# applying blur softens the pixels which results in softened edges when applying canny transform\n",
    "def gaussian_blur(image, kernel_size=5):\n",
    "    image_blurred = cv2.GaussianBlur(image, (kernel_size, kernel_size), 0)\n",
    "    return image_blurred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# apply Canny edge detection\n",
    "# extract edged from an image\n",
    "def canny_transform(image, min=50, max=200):\n",
    "    image_canny = cv2.Canny(image, min, max)\n",
    "    return image_canny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# create a polygon to isolate a region of interest in the image\n",
    "# areas outside of the polygon will be masked out, which is usefull when we try to identify lanes in the image\n",
    "# takes the vertices parameter: an array of data points(xy) that corresponds to the sides of the polygon\n",
    "def region_of_interest(image, vertices):\n",
    "    mask = numpy.zeros_like(image)   \n",
    "    \n",
    "    if len(image.shape) > 2:\n",
    "        channel_count = image.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "        \n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    \n",
    "    masked_image = cv2.bitwise_and(image, mask)\n",
    "    return masked_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# apply houghline transform to image\n",
    "# the output is the detected lines inside the region of interest mask we define\n",
    "# the input image is the output image of the region_of_interest function\n",
    "def houghline_transform(image, rho=0.4, theta=numpy.pi/180, threshold=15, min_line_len=20, max_line_gap=200):\n",
    "    houghlines = cv2.HoughLinesP(image, rho, theta, threshold, numpy.array([]), min_line_len, max_line_gap)  \n",
    "    return houghlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# convenience funtion\n",
    "# flattens an array of arrays\n",
    "def flatmap(items):                                                              \n",
    "    return [y for x in items for y in x]\n",
    "\n",
    "# returns the slope of a line\n",
    "def slope(xy):                                                                   \n",
    "    x1, y1, x2, y2 = xy[0]                                                       \n",
    "    return (y1 - y2) / (x1 - x2) \n",
    "\n",
    "# returns two arrays: [x data points of a line] and [y data points of a line]\n",
    "def get_points(line):                                                            \n",
    "    x1, y1, x2, y2 = line[0]                                                     \n",
    "    return [x1, x2], [y1, y2]  \n",
    "\n",
    "# returns a tuple of [x data points] and [y data points]\n",
    "# flattens the result of get_points: [[x1, x2], [x1, x2]] becomes [x1, x2, x1, x2 ...]\n",
    "def data_points(lines):                                                          \n",
    "    xs = [x[0] for x in map(get_points, lines)]                          \n",
    "    ys = [y[1] for y in map(get_points, lines)]                          \n",
    "    xs = flatmap(xs)                                                             \n",
    "    ys = flatmap(ys)                                                             \n",
    "    return xs, ys\n",
    "\n",
    "# filter houghlines according to their slope\n",
    "# slope < 0 are allocated in the left data points\n",
    "# slope > 0 are allocated in the right data points\n",
    "# returns a tuple with ([left x data points], [left y data points]) , ([right x data points], [right y data points])\n",
    "def split_lines(houghlines):\n",
    "    lx, ly= data_points(list(filter(lambda line: -0.899 < slope(line) < -0.5, houghlines)))\n",
    "    rx, ry= data_points(list(filter(lambda line: 0.899 > slope(line) > 0.5, houghlines)))\n",
    "    return (lx, ly), (rx, ry)\n",
    "\n",
    "# draws a line in the image\n",
    "# receives xy as parameter where xy is a tuple containing [x data points] and [y data points]\n",
    "# detect the average slope, intercept of the xy data points using polyfit\n",
    "# use the slope, intercept (m, b) to find the average x1, x2 data points\n",
    "# y1 is the height of the image and y2 is approx. half of the image\n",
    "def draw_lines(xy, image, color=(0, 200, 0), thickness=20):\n",
    "    height, width, _ = image.shape\n",
    "    x, y = xy\n",
    "    if len(x) > 0:                                                              \n",
    "        m, b = numpy.polyfit(x, y, 1)                                          \n",
    "        y1 = height\n",
    "        x1 = (y1 - b) / m                                                    \n",
    "        y2 = height/2 * 1.2                                                     \n",
    "        x2 = (y2- b) / m\n",
    "        cv2.line(image, (int(x1), height), (int(x2), int(y2)), color, thickness) \n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# output the result of lane detection pipeline\n",
    "# apply all the necessary color transforms on image before extracting lines\n",
    "# draws lines in a copy of original image and merge both as a result \n",
    "def process_image(image=test_image):\n",
    "    image_gray = gray_transform(image)\n",
    "    image_blur = gaussian_blur(image_gray)\n",
    "    image_edges = canny_transform(image_blur)\n",
    "    mask_height, mask_width, _ = image.shape\n",
    "    image_masked = region_of_interest(image_edges, numpy.array([[(0, mask_height), (mask_width/6, mask_height/2), (mask_width - (mask_width/6), mask_height/2), (mask_width, mask_height)]], dtype=numpy.int32))\n",
    "    houghlines = houghline_transform(image_masked)\n",
    "    lines = split_lines(houghlines)\n",
    "    image_lines = numpy.copy(image)*0                                             \n",
    "    [draw_lines(xy, image_lines) for xy in lines]\n",
    "    result = cv2.addWeighted(image, 1, image_lines, 1, 0)             \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x11b63cdd8>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot.imshow(process_image())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# apply process_image pipeline in video images\n",
    "def process_video(filename):\n",
    "    output = video_output_path + filename                          \n",
    "    clip1 = VideoFileClip(video_file_path + filename)                         \n",
    "    white_clip = clip1.fl_image(process_image)\n",
    "    white_clip.write_videofile(output, audio=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video test_videos_output/challenge.mp4\n",
      "[MoviePy] Writing video test_videos_output/challenge.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 251/251 [00:08<00:00, 29.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: test_videos_output/challenge.mp4 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "challenge = 'challenge.mp4'\n",
    "process_video(challenge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"test_videos_output/challenge.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(video_output_path + challenge))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video test_videos_output/solidWhiteRight.mp4\n",
      "[MoviePy] Writing video test_videos_output/solidWhiteRight.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 221/222 [00:03<00:00, 62.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: test_videos_output/solidWhiteRight.mp4 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "solidWhiteRight = 'solidWhiteRight.mp4'\n",
    "process_video(solidWhiteRight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"test_videos_output/solidWhiteRight.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(video_output_path + solidWhiteRight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video test_videos_output/solidYellowLeft.mp4\n",
      "[MoviePy] Writing video test_videos_output/solidYellowLeft.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 681/682 [00:11<00:00, 58.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: test_videos_output/solidYellowLeft.mp4 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "solidYellowLeft = 'solidYellowLeft.mp4'\n",
    "process_video(solidYellowLeft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"test_videos_output/solidYellowLeft.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(video_output_path + solidYellowLeft))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Pipeline description:\n",
    "\n",
    "The pipeline uses the techniques learned throughout the first lesson in term 1. The two most important ones in my understanding are Canny transform and Houghline transform. These form the base concept that helps in the detection of lanes in the road images.\n",
    "\n",
    "Canny transform outputs only the strongest edges in the image, which is essential for finding lines with the Houghline transform step in the pipeline. Houghline transform outputs all possible lines found in the canny image. However before and after Canny transform and Houghline transform we need to implement a few steps to output the final result seen in the videos above. In a nutshell these steps are:\n",
    "\n",
    "- Apply grayscale transform in image to better detect edged in Canny transform. High values (white) represent strong edges, dark values (black) represent soft spots.\n",
    "\n",
    "- Apply Gaussian blur in order to smooth the pixels. This improves the noise when we apply edge detection with Canny transform.\n",
    "\n",
    "- Use Canny transform to find strong edges in the image\n",
    "\n",
    "- Isolate a region of interest in the image where relevant lines should be detected by the Houghline transform. This step masks out unnecessary edges which can be considered lines in the Houghline step.\n",
    "\n",
    "- Apply Houghline transform to find lines in the region of interest. \n",
    "\n",
    "- Split the lines into left side of image and right side of image, where each side corresponds to left and right lane in the road. Line splitting is done by finding its slope value\n",
    "\n",
    "- Draw lines using numpy.polyfit to find the average slope of x y data points and the x = (y - b) / m to find extrapolate the lines to bottom and center of image. Here y is represented by the y value of our region of interest\n",
    "\n",
    "### Shortcomings:\n",
    "\n",
    "The pipeline detects the lanes on the road and displays a line on top of them quite well. However, there are some issues with this implementation:\n",
    "\n",
    "- The line could have a more smooth feel and flicker less. \n",
    "- Areas of the image where lane color blends with background causes the lane to either break or not show at all.\n",
    "- The code is not adaptive to road conditions. As an example, when the road has inconsistent lane intervals it becomes dificult to detect and draw lines. It's possible to tweak the Houghline parameters to get better results but it doesn't work equaly in all cases.\n",
    "\n",
    "Another big improvement is the detection of curves along the lines, which is not possible with this implementation.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
